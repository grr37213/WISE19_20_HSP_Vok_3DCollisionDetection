\label{sec:terminology}

Implementierungstechnisch schränkt eine Rechenmaschine die mathematischen Zahlenräume ein:
\begin{itemize}
\item Die Reelen Zahlen $\mathbb{R}$ beschränken sich auf Floating-Point-Datentypen, welche hier im weiteren mit $\mathcal{F} \subset \mathbb{R}$ bezeichnet werden
\item Integern $\mathbb{Z}$ sind maschinell in ihrer Darstellungsgröße beschränkt. Diese beschränkte Menge an Integern wird $\mathcal{I} \subset \mathbb{Z}$ genannt
\end{itemize}


\subsection{Zeit}
\label{sec:time}
\def\finite#1{\ooalign{\hfil$\mapstochar\mkern 3mu\mapstochar\mkern 5mu$\hfil\cr$#1$}}

Die Simulation läuft gezeitet ab. Es existieren dabei zwei relevante zeitliche Sequenzen:
\begin{enumerate}
\item Die durch maschinelle Abtastung diskrete Realzeit der echten Welt\\
	\begin{itemize}
	\item $T_r:=\langle t_{epoch}, ... , t_{max}\rangle ; t_{epoch}, t_{max}$ als minimal, bzw.~maximal darstellbare Zeit
	\item die in einer maschinellen Genauigkeit in Mikrosekunden $$\epsilon_t:=10^{-6}s ; \forall c \in \mathbb{Z}: T_r(c) + \epsilon_t = T_r(c+1)$$ gegeben ist
	\item und immer monoton wächst $\forall c \in \mathbb{Z}: T_r(c) < T_r(c+1)$. 
	\end{itemize}

\item Die Simulationszeit $T_s:=\langle t_{start}, ... , t_{end}\rangle; t_{start}, t_{end}$ als Start- und Endzeitpunkt der Simulation.
	\begin{itemize}
	\item Zwischen den beiden Zeitbasen besteht eine totale, nicht-injektive, surjektive Abbildung $\mathcal{T}:T_r \twoheadrightarrow T_s$
	\item Die Simulationszeit ist dadurch relativ zur Realzeit definiert $T_s:=\langle\mathcal{T}\rangle$
	\item Um die Kontinuität der Zeit herzustellen wird weiter eine Zeitrate $r_t:T_r\mapsto\mathcal{F}$ definiert, welche das relative verstreichen der Zeit in der Simulation steuert. 
	$$\forall t_{r0},  t_{r1} \in T_r ; t_{diff}=t_{r1}-t_{r0} :\mathcal{T}(t_{r1}) = \mathcal{T}(t_{r0}) + t_{diff}*r_t(t_{r1})$$ unter der Vorraussetzung, dass die Rate während aller Zeiten zwischen $t_{r0}$ und $t_{r1}$ gleich bleibt $\forall t \in [ t_{r0},t_{r1}]: r_t( t_{r0}) = r_t(t)$. Wird die Eigenschaft des Zeitflusses in der festgelegten Rate verletzt, werden die aktuellen Echtzeitanforderungen verletzt. \\
	Soll die Rate also geändert werden muss dies zu festgelegten Umschaltpunkten geschehen, welche die Simulationszeit in Zeitbereiche trennen, zwischen denen keine Berechnungsvorgänge zuverlässig durchführbar sind.\\
Beispiele für Raten sind 
\begin{itemize}
\item $r_t(x) = 1 \Leftrightarrow$ Simulation synchron zur Echtzeit
\item $r_t(x) = 0 \Leftrightarrow$ Simulation ist pausiert/läuft nicht
\end{itemize}
Technisch wird für große $|r_t|$ die Simulation schwierig, da viele Vorgänge schnell simuliert werden müssten. Diese werden daher vermieden.\\
Theoretisch kann die Rate auch negative Werte annehmen. Die Simulationszeit würde dann rückwärts laufen. Dieses Verhalten ist technisch durch die monoton steigende Realzeit nicht leicht in konsistenter Weise umzusetzen, da Realzeiteinflüsse durch Tasteneingaben existieren und soll daher hier ebenfalls vermieden werden.
	\end{itemize}
\end{enumerate}	

Funktionierende Komponenten, die dieses Verhalten abbilden existierten schon zu Beginn des Projektes. Dennoch wurden diese komplett überarbeitet, um dynamisch gegenüber Änderungen von Anforderungen in der Zukunft und konform zu Bibliotheken, insbesondere der Standardbibliothek in C++ zu sein. Simulationszeit und Realzeit wurden aus diesen Gründen in Form von C++ \texttt{std::chrono} Uhren reimplementiert. Ein Vorteil daraus ist die komfortable Verwendung von Datentypen für Zeitpunkte und Zeitspannen in verschiedenen Einheiten und Repräsentationen. Die Relevanz dieser konkreten Überarbeitung für dieses Projekt ist schwer einzuschätzen. Sie kann also auch nur marginal als Projektleistung angesehen werden.


\subsection{Tick \& Frame}
\input{tick.tex}

\subsection{Raum}
\label{sec:space}
Der geforderte 3D Raum kann durch 3-dimensionale Vektoren $\in \mathcal{F}^3$ in der Einheit Meter beschrieben werden.\\
Durch die Werteverteilung in $\mathcal{F}$ treten jedoch bei großen Räumen für Positionen mit großer Entfernung zum Ursprung $O$ Genauigkeitsdefizite auf, die zur Verletzung von Genauigkeitsanforderung führen können. Mögliche Floating-Point-Werte liegen dabei dichter beieinander, je näher am Ursprung \cite{floatdistribution}. Ein Beispiel für die Auswirkungen dieses Sachverhalts in Simulationen kann in der Quelle \cite{floatdistributionexample} betrachtet werden.\\
Physikalische Prozesse berechnet auf Basis von Positionen in $\mathcal{F}^3$ können daher inkonsistent in Abhängigkeit zum Ort im Raum sein.\\
Das Problem wird hier durch einen neuen Längendatentypen $\mathcal{S} : \mathcal{I} \times \mathcal{F}$ gelöst, welcher den Raum zunächst gleichmäßig durch $\mathcal{I}$ aufteilt und indiziert und $\mathcal{F}$ als Offset innerhalb seines Raumteils verwendet. Es wird daher eine Größe der initialen Aufteilung $size_{grid}$ definiert.\\
Die Umrechnung zu Metern ist dann: $$ meter: \mathcal{S} \mapsto \mathcal{F};  meter((i, f)) = i * size_{grid} + f * size_{grid}$$ 
Typischerweise gilt $f \in [0;1[$, um eine eindeutige Repräsentation für einen beschriebenen Punkt zu erhalten.

Diese Darstellung hat folgende weitere Vorteile
\begin{itemize}
\item Einfache Implementierung
\item Schnelle Indizierung der durch $\mathcal{I}$ indizierten Raumanteile für raumaufteilende Algorithmen
\end{itemize}

Absolute Positionen im Raum werden demnach mit Vektoren $s\in\mathcal{S}^3$ dargestellt. Für Berechnungen von Interaktionen zwischen Objekten werden Positionen zunächst relativiert, d.h. Positionen $p \in \mathcal{S}$ sollen zu $p_0$ relativ gesetzt werden, dann sind die relativen Positionen $p' = p - p_0$. Diese werden dann in in die für lokale Interaktionen sinnhafte  Einheit Meter $\mathcal{F}^3$ umgewandelt, um darauf Berechnungen durchzuführen. Man geht dabei davon aus, das relative Strecken zwischen Objekten kurz genug sind, sodass die Genauigkeitsänderung in $\mathcal{F}$ vernachlässigbar ist.\\
Effektiv ist dabei die Eigenschaft $\mathcal{F}\subset\mathcal{S}$ nicht gefordert, auch wenn sie in der in diesem Projekt verwendeten Implementierung prinzipiell gilt.

Implementierungstechnisch bestehen verschiedene Räume je nach Anwendungsfall, in denen Objekte durch Relativierung, Längenumrechnung und Transformation dargestellt werden.

\begin{enumerate}
\item Worldspace $= \mathcal{S}^3$, absolute Positionen von Objekten
\item Cameraspace $= \mathcal{F}^3$, Ursprung $O$ ist die Position der Kamera zum Rendern einer Szene, Objekte werden zur Kamera relativiert.
\item Viewspace $= \mathcal{F}^3$, Verzerrung durch die Kameralinse, um einen Blickwinkel auf einen Bildschirm anzupassen.
\item Objectspace $= \mathcal{F}^3$, Ursprung ist der vom Modell definierten Mittelpunkt eines Objektes (Massenmittelpunkt), zur Verarbeitung von physikalischen Objektinteraktionen wird ein Objekt zu einem anderen Objekt durch Transformation in dessen Objectspace relativiert.
\end{enumerate}

Auf diese Weise gelingt es selbst extreme absolute Entfernungen und Geschwindigkeiten im relativen akkurat zu behandeln.

Während ein Datentyp für $\mathcal{S}^3$ bereits zum Start des Projektes vorhanden war, wurde der Datentyp für $\mathcal{F}^3$ von einem selbst Definierten zu dem aus einer Bibliothek für lineare Algebra, GLM %TODO cite
, geändert, um Zugriff auf komplexe mathematische Operationen in korrekter Implementierung zu erlangen.

\subsection{Entitäten}
\label{sec:entity}
Entitäten sind der atomare Inhalt der Simulation. Es handelt sich dabei um eine Abstraktion für \glqq Etwas\grqq  in der Simulation. In der Realität suchen Physiker immer weiter \glqq Das [sie] erkenne[n], was die Welt im Innersten zusammenhält, ..\grqq [- J.W.v. Goethe, Faust, \glqq Nacht\grqq, Vers. 382]. Was in der Realität eine offene Frage ist, obwohl seit den Zeiten von Goethe in der Quantenphysik durchaus Fortschritte gemacht worden sind, muss für die Simulation jedoch eindeutig beantwortet werden, um eine quantifizierbare Menge an Instanzen eines Konzepts zu haben, die dann Simuliert werden können.\\
Quantenmechanische Prozesse sind, um die Illusion einer realen Welt aus der Perspektive eines Menschen herzustellen, um einiges zu rechenaufwändig für unsere Anforderungen. Man setzt die Abstraktion der atomaren Simulationseinheit also höher an, was praktisch zu vielen Spezialisierungen führt. Die gemeinsame Basis dieser Spezialisierungen wird hier \textit{Entity}( dt. Entität ) genannt.\\

Verschiedenartige Beispiele:
\begin{enumerate}
\item klassisch: 3D-Objekt mit einer Position, Rotation und Form, welches sich in Abhängigkeit der Zeit mit einer Geschwindigkeit bewegt.\\
\item formlose: Entität kann z.B.~ein Geräusch sein, welches in der Simulation durch seinen Quellort abstrahiert ist, sich ebenfalls bewegen kann, aber keine Rotation besitzen muss, oder zugehörig zu einer anderen Entität ist.
\item unphysikalisch: Logische Entitäten, die beispielsweise die Anwesenheit eines Objektes in einem bestimmten Raumabschnitt prüft und einer Subroutine das Ergebnis übermittelt.
\end{enumerate}
Die Abstraktion der Entität dient demnach als Schnittstelle für die Simulation, um Zeit (während eines Ticks) auf atomare Bestandteile der Simulation anzuwenden, und als Implementierungsplattform für die verschiedenen Anwendungsanforderungen der Simulation, bzw.~dem Verhalten des Simulationsinhalts.\\

Die Abstraktion durch Entitäten existiert bereits zu Beginn des Projektes.

\subsection{Objektform}
\label{object_form}
Die Form eines Objektes ist in einem hier rigiden, d.h. unveränderlichen Modell beschrieben, welche die Form relativ zum Ursprung $O$ ihres eigenen Objektraums angibt.
Für Modelle werden mathematisch oft kompakte Punktemengen verwendet. Wir denotieren diese kompakten Modelle zugehörig zum Objekt $o$ als $ K_o \subseteq \mathcal{F}$.\\

Durch die kompakte Mengendarstellung führen Rechenoperationen mit Objekten auf maschinell relativ rechenaufwändige Mengenoperationen zurück. In der Computergraphik werden deshalb Objekte durch sogenannte Polygon-Meshes dargestellt. 
Für das Objekt $o$ ist eine Polygon-Mesh $M_o := (V_o, I_o); V \subseteq \mathcal{F}^3, I \subseteq [0, |V|-1]_\mathbb{N}^3 )$ beschreibt ein Polytop durch seine Eckpunkte $V_o$(Ecken, eng. \textit{vertices}), die durch 3-Gruppierungen ihrer Indices $I_o$ zu Dreiecksflächen verbunden sind.\\
Aus der Definition der Polygon-Mesh gehen implizit weitere Definitionen hervor:

\begin{enumerate}
\item Kanten (eng. \textit{edges}) $E_o = \{(v_a, v_b), (v_b, v_c),(v_c, v_a) | \{v_0, ...\} = V_o;(a, b, c) \in I\} $
, welche jeweils die Punkte $\mathcal{E}:E_o\mapsto\mathcal{F}^3; \mathcal{E}((v_a, v_b)) = \{v_a + (v_b-v_a)* k; k \in [0,1]\} $ im Raum einnehmen.
\item Flächen (eng. \textit{areas})$ A_o = \{(v_a, v_b, v_c) | \{v_0, ... \} = V(o, t); (a, b, c) \in I\} $,\\
welche jeweils die Punkte $\mathcal{A}:A_o\mapsto\mathcal{F}^3; \mathcal{A}((v_a, v_b, v_c)) = \{v_a + (v_b-v_a)* k + (v_c-v_a)*l; (k+l) \in [0,1]\} $ im Raum einnehmen.
\item Gesamtpunktemenge $G_o = V_o \cup (\bigcup_{e\in E_o} \mathcal{E}(e)) \cup (\bigcup_{a\in A_o} \mathcal{A}(a)) $
\item Praktisch immer gilt: $V_o \subset (\bigcup_{e\in E_o} \mathcal{E}(e)) \subset (\bigcup_{a\in A_o} \mathcal{A}(a)) = G_o \subset K_o$
\item Die Gesamtpunktemenge enthält zu allen Zeiten $t$ mindestens die Objekthülle $\mathcal{H}: \mathcal{F}^3 \mapsto \mathcal{F}^3, \forall o\in OBJ: \mathcal{H}(K_o) \subseteq G_o$ die den eingenommenen Raum des Objekts/Modells vom übrigen Raum durch Flächen abgrenzt.
\end{enumerate}

Vorteile \& Nachteile dieser Darstellung o.B.d.A:
\begin{itemize}
\item [+]Kürzere Iterationslängen im Vergleich zu kompakten Punktmengen: $V_o \ll G_o \ll K_o$
\item [+]Berechnungen durch relativ schnelle klassische Vektorarithmetik, Skalar- , Kreuzprodukte statt Mengenoperationen.
\item [-]Verlust der Information von Innen \& Außenseite am Hüllobjekt.
\item [-]Zum sinnvollen Einsatz von Polygon-Meshes ist die verwendbare Menge an Objekten auf Polytope beschränkt. Eine schwierig darstellbare Objektform sind beispielsweise Ellipsoide ($|V_o|$ geht dann gegen $|G_o|$).
\end{itemize}

Während semantisch von der Simulation die kompakte Repräsentation eines Objektes $K_o$ respektiert werden muss, rechnet diese tatsächlich mit gegebenem $G_o$ welches in den meisten Kontexten genügt.

Zu Beginn des Projektes waren Meshes nur rudimentär zu 3D-Anzeigezwecken vorhanden. Modelle wurden daher im Rahmen dieses Projektes als Schnittstelle zur Objektform eingefügt, welche Methoden bereitstellt, um diese für weitere Subroutinen zu erhalten.

\subsection{Objektplatzierung}
\label{sec:objects_sim}

Objekte $o\in OBJ$ müssen nun in der Simulation absolut im Worldspace $\mathcal{S}^3$ platziert werden, sollen sonst für Berechnungen aber in relativen Räumen $\mathcal{F}^3$ behandelt werden. Es werden dafür zunächst absolute Beschreibungskriterien für Objekte angelegt.
\begin{itemize}
\item Raumposition zu Beginn eines Ticks $pos : OBJ \times \delta \mapsto \mathcal{S}^3$
\item Ausrichtung zu Beginn eines Ticks $rot : OBJ \times \delta \mapsto \mathcal{F}^3$. Der Vektor $(x, y, z) \in\mathcal{F}^3$ wird für die Drehung um x (Radialmaß) für die Drehung um die x-Achse relativ zum Raum definiert, bzw. y und z analog. Andere etablierte Formate, wie Quaternionen, werden hier nicht verwendet.
\end{itemize}
Die Kontinuitätseigenschaft $\delta_{j1} = \delta_{(j+1)0}$ ermöglicht die Übernahme/Speicherung des Wertes zu Tickbeginn aus dem letzten Tick.

Objekte sind in der Simulation zusätzlich zeitlichen Änderungen unterlegen.
An dieser Stelle wird festgelegt: Während eines Ticks ändern sich diese konstanten zeitlichen Änderungsgrößen nicht und werden daher ebenfalls pro Tick definiert.\\
 Es wird sich hier auf
\begin{enumerate}
\item Geschwindigkeit $v: OBJ \times \delta \mapsto \mathcal{S}^3$  und
\item Winkelgeschwindigkeit $\omega : OBJ \times \delta \mapsto \mathcal{F}^3 $
\end{enumerate}
beschränkt.

Durch die Kenntnis des räumlichen Objektzustandes zu Beginn eines Ticks, können durch die zeitlichen Änderungsgrößen nun sämtliche Zustände während des Ticks errechnet werden.
Dies wird unter Zuhilfenahme von Transformationsmatrizen $Q: OBJ \times \Upsilon_{\delta_i} \mapsto \mathcal{F}^{4\times 4}$ bewerkstelligt. Mit der Hilfe der Matrizen können die einem Objekt zugeordneten Punkte, seien dies $V_o, K_o$ usw., zu ihrer neuen Position zum gegebenen Zeitpunkt transformiert werden. Transformationsmatrizen sind typischerweise im Kontext der Computergrafik und Simulation von 3D-Räumen $4\times 4$ gewählt, um z.B. auch Translation zu realisieren \cite[ch. 4.4.1, p.76]{fourcrossfour}. Wir beschreiben dazu die 
Translationsmatrix, die aus einer Position, und die Rotationsmatrix, die aus einer Rotationsanweisung hervorgeht $Q_{trans}, Q_{rot}:\mathcal{F}^3 \mapsto \mathcal{F}^{4\times 4}$. Beide dieser Funktionen, insbesondere $Q_{trans}$ sind für $\mathcal{F}^3$ anstatt für $\mathcal{S}^3$ definiert, denn es wird erwartet, dass für die Berechnung zu einem relativ nahen Punkt $P \in\mathcal{S}^3$ relativiert und daraufhin in $\mathcal{F}^3$ durch die Funktion $meter$ umgewandelt wird.\\
Sei $o \in OBJ; pos = pos(o, \delta_i); v = v(o, \delta_i); rot = rot(o, \delta_i); \omega = \omega(o, \delta_i)$, dann gilt
$Q(o, t) = Q_{trans}(meter(pos + v * (t-t_0))) * Q_{rot}(rot + \omega * (t - t_0))$.\\
Praktisch wird im Projekt hier keine Translationsmatrix direkt verwendet. Stattdessen wird Translation durch schlichte Vektoraddition realisiert (Es gilt typischerweise $\forall p \in\mathbb{R}^3, move \in \mathbb{R}^3 : p * Q_{trans}(move) = p + move$). Der Grund hierfür liegt im Codedesign.\\
Bei der Relativierung von Objekten, welche hier als $o_1 - o_0$ denotiert wird, werden die Beschreibungskriterien beider Objekte mit denen eines Objektes $o_0$ jeweils subtrahiert. Die relative Transformationsmatrix kann wie folgt beschrieben werden:
\begin{align}
R: OBJ^2 \times \Upsilon_{\delta_i} \mapsto \mathcal{F}^{4\times 4}; R(o_1, o_0, t) = Q(o_1 - o_0, t) = \\
Q_{trans}( meter(  pos(o_1, t)-pos(o_0, t) ) + meter(v(o_1, t)-v(o_0, t)) * (t-t_0) ) \\
* Q_{rot}((rot(o_1, t)-rot(o_0, t)) + (\omega(o_1, t)-\omega(o_0, t)) * (t-t_0))= I_4
\end{align}
Ein Vorteil besteht dabei, dass bei Relativierung eines Objektes zu sich selbst dabei die Identitätsmatrix $I_4 = R(o_0, o_0, t) \forall t$ entsteht. Auf entsprechenden Modellpunkten von $o_0$ muss dann keine Operation ausgeführt werden, da $\forall p\in \mathbb{F}^3: p*I_4=p$. Dadurch kann bei der Berechnung einer Interaktion zwischen zwei Objekten, bei der u.U.~ viele Modellpunkte Transformiert werden müssen, die Hälfte der Transformationen gespart werden, indem direkt zu einem der beiden Objectspaces relativiert wird.\\
Zur Vereinfachung wird für alle Punktmengen $X_o$ zu einem Objekt $o$ die Notation $X_{o, t} = X_o * Q(o, t)$ und für relative Transformationen $X_{o_1, t, o_0} = X_{o_1} * R(o_1, o_0, t)$ verwendet, sodass z.B. die Transformierte Menge der Eckpunkte von $o$ zu Tickzeitpunkt $t$ als $V_{o,t}$ beschrieben werden kann.

Wir schreiben schon zu Beginn des Projektes die Position einer jeden Entität zu. Entitäten, die ein dreidimensionales Objekt darstellen, verwalten daher Rotation eigenständig. Solche Typen an Entitäten wurden im Rahmen dieses Projektes erstellt, die genaue Arithmetik dazu recherchiert und versucht in ein performantes Design zu packen. Insbesondere wurden dabei Bemühungen gemacht, durch Rotation veränderte Vertexpositionen relativ zum Ursprung des eigenen Objectspace nicht unnötig doppelt auszurechnen, was zu einer Lazy-Computing-Struktur führte.

\subsection{Hitbox}
\input{hitbox.tex}
\subsection{Hüllkörper}
\input{bounding_box.tex}

